üß† **√Årvore de Regress√£o (Decision Tree Regressor)**

**A √Årvore de Regress√£o √© um modelo supervisionado usado para prever valores cont√≠nuos.** Ela divide o espa√ßo de entrada em regi√µes baseadas em regras de decis√£o, aprendidas diretamente dos dados, sem necessidade de rela√ß√£o linear.

---

üß© **Como funciona**

1. **Divide recursivamente** os dados com base em regras de "maior redu√ß√£o do erro" (ex: MSE).
2. Em cada n√≥, escolhe o **melhor atributo e ponto de divis√£o**.
3. Para prever, segue o caminho da √°rvore at√© uma **folha**, que cont√©m o valor m√©dio dos dados daquele grupo.

---

‚öôÔ∏è **Hiperpar√¢metros principais**

* `max_depth`: profundidade m√°xima da √°rvore.
* `min_samples_split`: n√∫mero m√≠nimo de amostras para dividir um n√≥.
* `min_samples_leaf`: n√∫mero m√≠nimo de amostras em uma folha.
* `max_features`: n√∫mero de features consideradas em cada split.
* `criterion`: m√©trica usada para divis√£o (`squared_error`, `mae`, etc.).

---

üìè **Pr√©-processamento essencial**

* **N√£o precisa de normaliza√ß√£o/padroniza√ß√£o**.
* **Lida com dados num√©ricos e categ√≥ricos** (categ√≥ricos precisam ser codificados).
* **N√£o lida com valores ausentes nativamente** ‚Üí precisa imputar.
* **Pouco sens√≠vel a outliers** comparado √† Regress√£o Linear.
* **Desbalanceamento de dados** pode afetar divis√µes iniciais ‚Äî menos comum em regress√£o, mas ainda pode ocorrer.

---

üìä **M√©tricas de avalia√ß√£o (regress√£o)**

* **MAE**, **MSE**, **RMSE**, **$R^2$**.
* **Valida√ß√£o cruzada** √© recomendada para evitar overfitting e avaliar estabilidade do modelo.
* Pode usar **podas (pruning)** ou limitar profundidade para melhorar generaliza√ß√£o.

---

‚úÖ **Vantagens**

* **N√£o assume linearidade** ou distribui√ß√£o espec√≠fica dos dados.
* F√°cil de **interpretar e visualizar**.
* Funciona bem com **intera√ß√µes entre vari√°veis**.
* **Capaz de modelar rela√ß√µes n√£o lineares**.
* Baixa necessidade de pr√©-processamento.

---

‚ö†Ô∏è **Desvantagens**

* **Propensa a overfitting** em profundidades grandes (modelo muito espec√≠fico).
* Pequenas mudan√ßas nos dados podem gerar √°rvores bem diferentes.
* **Menor performance geral** comparado a ensembles como Random Forest ou Boosting.
* **N√£o lida com valores ausentes** diretamente.

---

‚öôÔ∏è **Desempenho computacional**

* **R√°pida para treinar e prever** em datasets pequenos a m√©dios.
* Pode ser **ineficiente com muitos atributos** (alta dimensionalidade).
* Treinamento e predi√ß√£o s√£o **leves**, mas o tamanho da √°rvore pode crescer r√°pido sem restri√ß√µes.

---

üìå **Quando aplicar**

* Quando se quer **modelo interpret√°vel** com **pouco pr√©-processamento**.
* Quando os dados t√™m **rela√ß√µes n√£o lineares ou intera√ß√µes complexas**.
* Como **baseline explicativo** antes de usar ensembles.
* Em problemas de regress√£o **simples ou de m√©dia complexidade**.
