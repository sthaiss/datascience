üß† **Regress√£o Log√≠stica (Logistic Regression)**

**A Regress√£o Log√≠stica √© um modelo supervisionado utilizado para tarefas de classifica√ß√£o bin√°ria ou multiclasse.** Apesar do nome, √© um modelo de **classifica√ß√£o**, que estima a **probabilidade de pertencimento a uma classe**, usando a **fun√ß√£o log√≠stica (sigmoide)**.

---

üß© **Como funciona**

1. Calcula uma **combina√ß√£o linear dos atributos**:
   $z = w_0 + w_1x_1 + w_2x_2 + \ldots + w_nx_n$
2. Aplica a **fun√ß√£o sigmoide** para transformar o valor em uma **probabilidade**:
   $\hat{y} = \frac{1}{1 + e^{-z}}$
3. Define um **limiar de decis√£o** (ex: 0.5) para classificar.

---

‚öôÔ∏è **Hiperpar√¢metros principais**

* `penalty`: tipo de regulariza√ß√£o (`l1`, `l2`, `elasticnet`).
* `C`: for√ßa da regulariza√ß√£o (inverso de Œª ‚Üí **quanto menor o C, maior a penaliza√ß√£o**).
* `solver`: algoritmo de otimiza√ß√£o (ex: `liblinear`, `saga`, `lbfgs`).
* `max_iter`: n√∫mero m√°ximo de itera√ß√µes.
* `class_weight`: √∫til em problemas com classes desbalanceadas.

---

üìè **Pr√©-processamento essencial**

* **Sens√≠vel √† escala** dos atributos ‚Üí **padroniza√ß√£o** recomendada.
* **N√£o lida com valores ausentes** ‚Üí √© necess√°rio **imputar antes**.
* **Pode ser sens√≠vel a outliers**, que afetam os coeficientes.
* Funciona melhor com **atributos informativos e linearmente separ√°veis**.
* Em caso de **classes desbalanceadas**, usar `class_weight='balanced'` ou t√©cnicas de resampling.

---

üìä **M√©tricas de avalia√ß√£o**

* **Acur√°cia, Precis√£o, Recall, F1-score, ROC-AUC, Matriz de Confus√£o**.
* Curvas de **precis√£o-recall** s√£o √∫teis em contextos desbalanceados.
* **Valida√ß√£o cruzada** recomendada para avaliar generaliza√ß√£o e ajustar hiperpar√¢metros.

---

‚úÖ **Vantagens**

* **Simples, r√°pido e interpret√°vel** (coeficientes t√™m significado).
* **Funciona bem com poucos dados e features relevantes**.
* F√°cil de regularizar para **evitar overfitting**.
* Serve como **baseline forte** para compara√ß√£o com modelos mais complexos.

---

‚ö†Ô∏è **Desvantagens**

* **Assume separabilidade linear** ‚Üí pode ter desempenho ruim com dados n√£o lineares.
* **Sens√≠vel a outliers e multicolinearidade**.
* N√£o trata **valores ausentes diretamente**.
* Pode sofrer com **underfitting** se o modelo for mal especificado.
* **Desempenho limitado em problemas complexos ou com muitos atributos irrelevantes**.

---

‚öôÔ∏è **Desempenho computacional**

* **Treinamento e predi√ß√£o r√°pidos**, mesmo em datasets grandes.
* Baixo consumo de recursos ‚Üí ideal para **produ√ß√£o em larga escala**.
* **Escala bem com n√∫mero de amostras**, mas pode ser impactado por **alta dimensionalidade** sem regulariza√ß√£o adequada.

---

üìå **Quando aplicar**

* Quando se deseja um modelo **simples, r√°pido e interpret√°vel**.
* Como **baseline em tarefas de classifica√ß√£o bin√°ria**.
* Quando os dados s√£o **linearmente separ√°veis** ou pr√≥ximos disso.
* Quando **explicabilidade dos coeficientes** √© importante para o neg√≥cio.


