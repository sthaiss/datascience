üß† **SVM - Support Vector Machine**

**SVM √© um algoritmo supervisionado poderoso para classifica√ß√£o e regress√£o**, especialmente eficaz em espa√ßos de alta dimensionalidade. Ele busca encontrar o **hiperplano √≥timo que separa as classes com a maior margem poss√≠vel** entre os dados.

Pode ser usado para **classifica√ß√£o bin√°ria, multiclasse (via One-vs-Rest)** e regress√£o (SVR).

---

üß© **Como funciona**

1. Identifica os **vetores de suporte**: pontos mais pr√≥ximos da fronteira de decis√£o.
2. Encontra o **hiperplano que maximiza a margem** entre as classes.
3. Pode usar **fun√ß√µes kernel** para projetar os dados em espa√ßos de maior dimens√£o e **lidar com dados n√£o linearmente separ√°veis**.

---

‚öôÔ∏è **Hiperpar√¢metros principais**

* `C`: controla a penaliza√ß√£o de erros (trade-off entre margem e erro).
* `kernel`: tipo de fun√ß√£o usada para transformar os dados (`linear`, `rbf`, `poly`, `sigmoid`).
* `gamma`: define a influ√™ncia de um ponto de treino (para kernels n√£o lineares).
* `degree`: grau do polin√¥mio (se `kernel='poly'`).
* `class_weight`: √∫til para tratar **classes desbalanceadas**.

---

üìè **Pr√©-processamento essencial**

* **Exige padroniza√ß√£o dos dados** (SVM √© sens√≠vel √† escala).
* **N√£o lida com valores ausentes** ‚Üí imputa√ß√£o necess√°ria.
* Pode ser **sens√≠vel a outliers**, que influenciam o hiperplano.
* **Dados desbalanceados** afetam a fronteira ‚Üí usar `class_weight='balanced'` ou t√©cnicas de reamostragem.

---

üìä **M√©tricas de avalia√ß√£o**

* **Acur√°cia, Precis√£o, Recall, F1-score, ROC-AUC, Matriz de Confus√£o**.
* **Valida√ß√£o cruzada** √© essencial, especialmente para **ajuste fino de C e gamma**.
* Grid search com valida√ß√£o cruzada ajuda a encontrar o melhor conjunto de hiperpar√¢metros.

---

‚úÖ **Vantagens**

* **Alta performance em espa√ßos de alta dimensionalidade**.
* Funciona bem com **margem clara entre classes**.
* **Kernel trick** permite aplicar SVM em problemas **n√£o lineares**.
* Modelo **robusto contra overfitting** com os hiperpar√¢metros corretos.

---

‚ö†Ô∏è **Desvantagens**

* **Lento em grandes volumes de dados** (custo quadr√°tico/c√∫bico).
* Dif√≠cil de interpretar e explicar.
* **Sens√≠vel a outliers** e **dados desbalanceados**.
* N√£o lida com **valores ausentes diretamente**.
* Pode sofrer com **underfitting** se mal parametrizado ou com kernel inadequado.

---

‚öôÔ∏è **Desempenho computacional**

* **Treinamento pode ser lento** em datasets grandes ou com muitos atributos.
* **Predi√ß√£o √© mais r√°pida**, mas depende do n√∫mero de vetores de suporte.
* Escala mal com muitos dados, mas funciona bem com **alta dimensionalidade e poucos exemplos**.
* Ideal para conjuntos de dados **m√©dios ou pequenos**.

---

üìå **Quando aplicar**

* Quando h√° **clara separa√ß√£o entre classes** ou **poucos dados, mas com muitas features**.
* Quando voc√™ precisa de um modelo **potente e com boa generaliza√ß√£o**.
* Para problemas **n√£o lineares**, com uso de **kernels apropriados**.
* Quando o foco √© **precis√£o**, mesmo com maior custo computacional.
